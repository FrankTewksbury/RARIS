---
name: gemini-model-rules
description: Google Gemini-Specific Implementation Patterns for Research Graph RAG
alwaysApply: false
---

# Gemini Model Rules
# Google Gemini-Specific Implementation Patterns

---

## 1. Model Selection

### Available Models (Gemini 3 Series - Latest)
| Model ID | Use Case | Thinking Budget | Notes |
|----------|----------|-----------------|-------|
| `gemini-3-pro-preview` | **DEFAULT** - Complex reasoning, ontology discovery, schema analysis | 32768 | Most capable, highest accuracy |
| `gemini-3-flash-preview` | High-speed enumeration, batch processing, entity extraction | 16384 | Fast, cost-effective |

### Task-Based Selection for Research Graph RAG
| Task Type | Model | Thinking Budget | Notes |
|-----------|-------|-----------------|-------|
| Entity Extraction | `gemini-3-flash-preview` | 8192 | Fast batch processing |
| Relation Extraction | `gemini-3-flash-preview` | 8192 | Volume enumeration |
| Theme Classification | `gemini-3-flash-preview` | 4096 | Quick categorization |
| Complex Summarization | `gemini-3-pro-preview` | 24576 | Deep reasoning required |
| Document Analysis | `gemini-3-pro-preview` | 32768 | Structure analysis |

### Deprecated Models - DO NOT USE
- `gemini-1.5-pro` → Use `gemini-3-pro-preview`
- `gemini-1.5-flash` → Use `gemini-3-flash-preview`
- `gemini-pro` → Use `gemini-3-pro-preview`

---

## 2. API Implementation (Python)

### Client Initialization
```python
from google import genai
from google.genai import types
import os

client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
```

### Basic Request Pattern
```python
def call_gemini(
    prompt: str,
    model: str = "gemini-3-pro-preview",
    thinking_budget: int = 24576,
    temperature: float = 0.7
) -> str:
    """Make a request to Gemini API."""
    print(f"[INFO] Initializing Gemini Model: {model}")
    
    config = types.GenerateContentConfig(temperature=temperature)
    config.thinking_config = types.ThinkingConfig(thinking_budget=thinking_budget)
    
    response = client.models.generate_content(
        model=model,
        contents=prompt,
        config=config
    )
    return response.text
```

### JSON Mode Enforcement
```python
config = types.GenerateContentConfig(
    response_mime_type="application/json",
    response_schema={
        "type": "object",
        "properties": {
            "entities": {"type": "array"},
            "relations": {"type": "array"}
        },
        "required": ["entities"]
    }
)
```

---

## 3. Thinking Budget Configuration

### Budget Guidelines
| Complexity | Thinking Budget | Use Case |
|------------|-----------------|----------|
| Minimal | 0-1024 | Simple lookups, formatting |
| Low | 4096 | Basic Q&A, theme classification |
| Medium | 8192 | Entity extraction, summaries |
| High | 16384 | Complex analysis, batch enumeration |
| Very High | 24576 | Deep reasoning, problem solving |
| Maximum | 32768 | Ontology discovery, schema analysis |

---

## 4. Embeddings

### Embedding Model
Use `text-embedding-005` for high-quality semantic embeddings:

```python
def get_embedding(text: str) -> list[float]:
    """Generate embedding for text using Gemini."""
    response = client.models.embed_content(
        model="text-embedding-005",
        content=text
    )
    return response.embedding
```

---

## 5. Error Handling

### SDK Exception Model (current: `python-genai`)

Use `google.genai.errors` — NOT the legacy `google.api_core.exceptions`.

```python
from google.genai import errors

# errors.APIError      — base class for all API errors; has .code (int HTTP status)
# errors.ClientError   — 4xx errors (subclass of APIError)
# errors.ServerError   — 5xx errors (subclass of APIError)
```

### Error Code Matrix and Action Policy

| HTTP Code | gRPC Status | Action | Notes |
|-----------|-------------|--------|-------|
| `400 INVALID_ARGUMENT` | `INVALID_ARGUMENT` | **Fail-fast** | Fix request shape |
| `400 FAILED_PRECONDITION` | `FAILED_PRECONDITION` | **Fail-fast** | Check billing/env |
| `401 UNAUTHENTICATED` | `UNAUTHENTICATED` | **Fail-fast** | Check API key |
| `403 PERMISSION_DENIED` | `PERMISSION_DENIED` | **Fail-fast** | Check model entitlement/quota |
| `404 NOT_FOUND` | `NOT_FOUND` | **Fail-fast** (+ optional model alias remap) | Verify model ID |
| `429 RESOURCE_EXHAUSTED` | `RESOURCE_EXHAUSTED` | **Retry + backoff + downgrade** | Quota or rate limit |
| `500 INTERNAL` | `INTERNAL` | **Retry + backoff** | Transient server error |
| `502 BAD_GATEWAY` | — | **Retry + backoff** | Infrastructure transient |
| `503 UNAVAILABLE` | `UNAVAILABLE` | **Retry + backoff + downgrade** | Service overload |
| `504 GATEWAY_TIMEOUT` | — | **Retry + backoff + downgrade** | Request timed out at infra |
| Transport/OS error | — | **Retry + backoff** | Network blip |

**Retryable codes:** `{429, 500, 502, 503, 504}` + transient transport exceptions.
**Downgrade-eligible codes:** `{429, 503, 504}` — additionally advance to next model in fallback chain.
**Fail-fast codes:** `{400, 401, 403, 404}` — raise immediately; do not retry.

### Resilient Async Call Pattern

```python
import asyncio
import random
from google.genai import errors

_RETRYABLE_CODES = frozenset({429, 500, 502, 503, 504})
_DOWNGRADE_CODES = frozenset({429, 503, 504})
_MAX_ATTEMPTS = 4
_BASE_DELAY_S = 1.0
_MAX_DELAY_S = 32.0

def _error_code(exc: Exception) -> int | None:
    code = getattr(exc, "code", None)
    return code if isinstance(code, int) else None

async def call_with_resilience(client, contents, config, fallback_chain: list[str]) -> str:
    last_exc: Exception = RuntimeError("no attempts")
    model_idx = 0
    for attempt in range(_MAX_ATTEMPTS):
        model = fallback_chain[min(model_idx, len(fallback_chain) - 1)]
        try:
            response = await client.aio.models.generate_content(
                model=model, contents=contents, config=config
            )
            return response.text or ""
        except errors.APIError as exc:
            code = _error_code(exc)
            last_exc = exc
            if code not in _RETRYABLE_CODES:
                raise  # fail-fast: 400/401/403/404
            delay = min(_BASE_DELAY_S * (2 ** attempt) + random.uniform(0, 1.0), _MAX_DELAY_S)
            if code in _DOWNGRADE_CODES and model_idx < len(fallback_chain) - 1:
                model_idx += 1  # advance to next model in chain
            await asyncio.sleep(delay)
        except (TimeoutError, ConnectionError, OSError) as exc:
            last_exc = exc
            delay = min(_BASE_DELAY_S * (2 ** attempt) + random.uniform(0, 1.0), _MAX_DELAY_S)
            await asyncio.sleep(delay)
    raise last_exc
```

### Required Telemetry Fields (per retry attempt)

All retry/fallback log entries MUST include:

| Field | Type | Description |
|-------|------|-------------|
| `runId` | str | Active discovery run identifier |
| `manifestId` | str | Target manifest |
| `stage` | str | Pipeline stage (e.g. `program_enumerator`) |
| `provider` | str | `gemini` |
| `model` | str | Model used for this attempt |
| `errorCode` | int \| None | HTTP status code |
| `retryAttempt` | int | 1-based attempt index |
| `fallbackModel` | str \| None | Model to be tried next, or `null` |
| `delayMs` | float | Backoff delay applied before next attempt |

### Model Downgrade / Fallback Policy

- **Configuration:** Set `GEMINI_FALLBACK_MODELS` as a comma-separated ordered list.
  - Example: `gemini-3-pro-preview,gemini-3-flash-preview,gemini-2.5-flash`
- **Trigger:** Only on downgrade-eligible codes (`429`, `503`, `504`).
- **Deterministic fail-fast:** Auth and request-shape errors (`400`, `401`, `403`, `404`) MUST NOT trigger fallback — fix the root cause instead.
- **Logging:** Every downgrade MUST emit a structured log line with `model`, `fallbackModel`, `errorCode`, and `retryAttempt`.

### Deprecated Import — DO NOT USE

```python
# WRONG — legacy SDK, not used with python-genai
from google.api_core.exceptions import ResourceExhausted, DeadlineExceeded
```

---

## 6. Quick Reference

### Environment Variable
```
GEMINI_API_KEY=your_api_key_here
```

### Minimal Working Example
```python
import os
from google import genai
from google.genai import types

client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

response = client.models.generate_content(
    model="gemini-3-flash-preview",
    contents="Extract entities from this text: ...",
    config=types.GenerateContentConfig(
        thinking_config=types.ThinkingConfig(thinking_budget=8192)
    )
)

print(response.text)
```
